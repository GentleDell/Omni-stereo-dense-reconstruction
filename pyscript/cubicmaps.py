#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Created on Sat Mar  9 12:00:57 2019

@author: zhantao
"""
import warnings
from typing import Optional

import cv2
import cam360
import numpy as np
from spherelib import pol2eu
from read_dense import read_array
 
from interpolation.splines import CubicSplines



class CubicMaps:
    """
    It implements sphere2cubemap projection and cubemap2sphere projection.
    The cubemap2sphere projection has two versions: fast ver. and standard ver.

    It stores:
    -   the distance between the projected plane to the sphere center,
    -   the 6 cube maps,
    -   the 6 depth maps,
    -   the omnidirectional image/depthmap obtained from the above cubemaps.

    The cube maps and cubic depthmaps are stored as a list:

    -   [ 0th:  back  |  1st:  left  |  2nd:  front  |  3rd:  right  |  4th:  top  |  5th:  bottom ].

    In particular, for each pixel on the depthmap, it's depth means the distance between the 3D point 
    to the camera plane. The depthmaps always have only 1 channel.
    """
    def __init__(self, dist: float = 1):
        """
            It initializes the object.
                
            Parameters
            ----------    
            dist: float
                distance between the tangent plane and the center of the sphere 
                
        """
        
        # this is used in cubic projection, denoting the distance bewteen sphere center to the projection plane 
        self._dist = dist
        
        # list to save cube maps
        self._cubemap = []
        
        # list to save cube depthmaps
        self._depthmap = []
        
        # the omnidirectional image generated by projecting cubemaps/cube depthmaps back to the sphere
        self._omnimage = None
         
        
    @property
    def omnimage(self) -> np.array:
        return self._omnimage
    
    @property
    def cubemap(self) -> list:
        return self._cubemap
    
    @property
    def depthmap(self) -> list:
        return self._depthmap
    
    def save_cubemap(self, path: str = './', prefix: str = '', index: list = [0,1,2,3,4,5]):
        '''
            It saves the indexed cubemaps to the given path and uses the given prefix as a part of the file name.
            
            Parameters
            ----------    
            path: str
                Where the cubemaps will be saved to.
                
            prefix: str
                The prefix that will be used as a part of the file names.
                
            index: list 
                The index of cubemaps to be saved.
            
            Examples
            --------
            >>> cubemap_obj.save_cubedepth(path = './data', prefix = 'test', index=[0,1,2,3]) 
        '''
        if len(self._cubemap) == 0:
            warnings.warn("No valid cube map!")
        else:
            if max(index) > len(self.cubemap):
                raise ValueError('Input ERROR! Invalid index')
            else:
                for ind in index:
                    file_name = path + prefix + '_view' + str(ind)+'.png'
                    cv2.imwrite(file_name, 255*np.flip(self.cubemap[ind],axis = 2))
    
    
    def save_cubedepth(self, path: str = './', prefix: str = '', index: list = [0,1,2,3,4,5], 
                       dist_to_radius: bool = False, camera_para: list = None):
        '''
            It saves the indexed cubic depthmaps to the given path and uses the given prefix as a part of the file name.
            
            Parameters
            ----------    
            path: str
                Where the cubemaps will be saved to.
                
            prefix: str
                The prefix that will be used as a part of the file names.
                
            index: list 
                The index of cubemaps to be saved.
                
            dist_to_radius: bool 
                Whether to convert the depth to radius.
            
            camera_para: list
                If the dist_to_radius is True, the necessary camera parameters are given in this list, 
                including: [focal length x, focal length y, camera center on rows, camera center on columns]
            
            Examples
            --------
            >>> cubemap_obj.save_cubedepth(path = './', prefix = 'test_depth', index=[0,1,2,3], 
                                       dist_to_radius=True, camera_para=[267, 267, 256, 256])  
        '''
        if len(self._depthmap) == 0:
            warnings.warn("No valid depth map!")
        else:
            if max(index) > len(self.depthmap):
                raise ValueError('Input ERROR! Invalid index')
            else:
                if not dist_to_radius:
                    for ind in index:
                        file_name = path + prefix + '_depthview' + str(ind)+'.exr'
                        cv2.imwrite(file_name, self.depthmap[ind].astype(np.float32))
                elif dist_to_radius and camera_para is not None:
                    for ind in index:
                        file_name = path + prefix + '_depthview' + str(ind)+'.exr'
                        radius_depthmap = self.depth_trans(self.depthmap[ind], camera_para).astype(np.float32) 
                        cv2.imwrite( file_name, radius_depthmap)
                else:
                    raise ValueError('Input ERROR! Invalid focal length or camera center')
            
    def save_omnimage(self, path: str = './'):
        '''
            It saves the omnidirectional image obtained from 6 cubemaps.
            
            Parameters
            ----------    
            path: str
                Where the cubemaps will be saved to.
            
            Examples
            --------
            >>> cubemap_obj.save_omnimage(path = './')  
        '''
        if self._omnimage is None:
            warnings.warn("No valid omnidirectional image!")
        if self._omnimage.shape[2] == 3: 
            cv2.imwrite(path + "omni_image.png", 255*np.flip(self._omnimage,axis = 2))
        else: 
            cv2.imwrite(path + "omni_depthmap.exr", self._omnimage.astype(np.float32))
    
    
    def depth_trans(self, depthmap: np.ndarray=None, camera_parameters: list = None) -> np.ndarray:
        '''
            It converts a general depthmap to a radial depthmap. 
            (depth represents the distance between the 3D points and the sphere center)
            
            Parameters
            ----------    
            depthmap: np.ndarray
                Depthmap to be converted;
                
            camera_parameters: list
                Camera parameters to convert the depthmap: [fx, fy, cx, cy];
                
            Returns
            -------
            radius_depth : np.array
                Depthmap using radial distance as depth.
                
            Examples
            --------
            >>> self.depth_trans(self.depthmap[ind], camera_para)
        '''
        if depthmap is None or camera_parameters is None:
            raise ValueError('Input ERROR! Invalid input image or camera parameters')
        elif len(depthmap.shape) < 2:
            raise ValueError('Input ERROR! The input image should be a 2D matrix')
        elif sum(np.array(camera_parameters) <= 0) > 0:
            raise ValueError('Input ERROR! Invalid camera parameters')
        else:
            mat_3d = False
            if len(depthmap.shape) > 2:
                mat_3d = True
                depthmap = depthmap.squeeze(axis = 2)
                
            fx = camera_parameters[0]
            fy = camera_parameters[1]
            cam_center_row = camera_parameters[2]
            cam_center_col = camera_parameters[3]
            
            row_dist = np.arange(depthmap.shape[0]) - cam_center_row + 1
            row_dist_mat = np.tile( np.transpose([row_dist]), (1, depthmap.shape[1]))
            
            col_dst = np.arange(depthmap.shape[1]) - cam_center_col + 1
            col_dist_mat = np.tile( col_dst, (depthmap.shape[0], 1))
            
            radius_depth = depthmap * np.sqrt(1 + (row_dist_mat/fy)**2 + (col_dist_mat/fx)**2)
            
            if mat_3d:
                radius_depth = np.expand_dims(radius_depth, axis = 2)
            
        return radius_depth
    
    
    def cube2sphere_fast( self, cube_list: list = None, resolution: tuple = (256, 512), order: Optional[list] = None):
        """
            It projects a list of six cubic images to an omnidirectional image. 
            As it passes one image at a time, it only needs 6 passes to obtain the omni image and so it is faster than the cube2sphere_std().
                
            Parameters
            ----------    
            cube_list : a list of 6 cubic images
                If 'position' is not given, then the order of the 6 images has to be:
                [ 0th:  back  |  1st:  left  |  2nd:  front  |  3rd:  right  |  4th:  top  |  5th:  bottom ]
                
            resolution : tuple
                The required resolution for the ouput omnidirectional image, default is 256x512 (theta, phi).
                
            order : a list of integer 
                For each image in the cube_list, the number denotes the direction of the image.
                [0,1,2,3,4,5] -> default order
                [5,4,3,2,1,0] -> inverse order, i.e. the first image in the cube_list is the bottom and the second image is the top etc. 
                If there are only 3 images in the cube_list, then only the first 3 numbers will be considered.
    
            Returns
            -------
            Omni_image : np.array
                An omnidirectional image generated from the given 6 cubic images.
            
            Examples
            --------
            >>> from DepthMap_Tools import Depth_tool
            >>> tool_obj = Depth_tool()
            >>> tool_obj.sphere2cube(Omni_obj)
            >>> Omni_new = tool_obj.cube2sphere_fast( tool_obj._cubemap ) 
        """
        # check the cube list, if it is empty, try to use the depth maps or cubic images of the object
        if cube_list is None:
            if len(self._depthmap) == 6:
                cube_list = self._depthmap.copy()
            elif len(self._cubemap) == 6:
                cube_list = self._cubemap.copy()
            else:
                raise ValueError('Bad input! Invalid input image list.')       
        
        # check the consistency of images' size
        for ind, cube in enumerate(cube_list):
            if cube.shape[:2] != cube_list[0].shape[:2]:            
                print('Bad input! All given images should have the same size.')
                return None
            # if is depth map from .exr file
            if len(cube.shape) == 2:      
                cube_list[ind] = np.expand_dims(cube, axis=2)
        
        # obtain input image size
        width  = cube_list[0].shape[1]
        height = cube_list[0].shape[0] 
        channel= cube_list[0].shape[2] 
        
        # parameters for cubicsplines
        up  = [2, 2]
        low = [0, 0]
        orders = [height, width]
        
        # create the Omnidirectional image'
        Omni_image = np.zeros([resolution[0]*resolution[1], channel])
        
        # reorder the cubelist
        if order is not None:
            if len(order) < len(cube_list):
                raise ValueError('Inpur Error! The length of "order" should be equal or larger than the length of "cube_list".') 
            temp = cube_list
            cube_list = [ [] for i in range(len(temp))]
            for ind, img in enumerate(temp):
                cube_list[ order[ind] ] = img         
        
        for face in range(len(cube_list)):
            # Create a spline approximation of the camera texture.
            spline = CubicSplines(low, up, orders, 
                                  np.reshape(cube_list[face], (height * width, channel)))
            
            points, mask_face  = self.spherical2img(face, resolution)
            Omni_image[ mask_face, :]  = spline.interpolate(points, diff=False)
            
        self._omnimage = None
        self._omnimage = Omni_image.reshape([resolution[0], resolution[1], -1])
        
    
    def spherical2img(self, face_num: int, resolution: np.array) -> np.array:
        """
            For each pixel on the unit sphere, this function computes the position of the pixel in corresponding cubic image.
                
            Parameters
            ----------    
            face_num : int
                The face number. [ 0:  back  |  1:  left  |  2:  front  |  3:  right  |  4:  top  |  5:  bottom ]
                
            resolution : tuple
                The required resolution for phi and theta.(theta, phi)
                
            Returns
            -------
            points : numpy.array 
                The positions (under image coordinate) of the points on sphere, with refer to the face_num.
                
            mask_face : numpy.array
                A mask vector for the image block on omnidirectional image corresponding to the face_num.
        """
        # generate sphere grids
        phi   = np.linspace(0, 2*np.pi, num = resolution[1])
        theta = np.linspace(0, np.pi  , num = resolution[0])
        grid_phi, grid_theta = np.meshgrid(phi, theta)
        
        # deal with the 4 horizontal surfaces
        if face_num < 4 and face_num >= 0:
            # generate mask using element wise bool operation
            if face_num == 0:
                mask_phi = (grid_phi - face_num*np.pi/2 < np.pi/4) + (grid_phi - face_num*np.pi/2 > -np.pi/4 + (face_num==0)*2*np.pi)
            else:
                mask_phi = (grid_phi - face_num*np.pi/2 < np.pi/4) * (grid_phi - face_num*np.pi/2 > -np.pi/4 + (face_num==0)*2*np.pi)
            mask_theta = (grid_theta > np.pi/4) * (grid_theta < 3*np.pi/4)
            mask_face  = mask_theta * mask_phi
            mask_face  = mask_face.flatten()   
            
            # slicing grids
            phi   = -( grid_phi.flatten()[mask_face] - face_num*np.pi/2 )
            theta = grid_theta.flatten()[mask_face]
            
            # normalized image coordinates
            u = 1 - np.tan(phi)
            v = 1 - np.sqrt(1 + np.power(np.tan(phi), 2))/np.tan(theta)
        
        # the top and bottom surface 
        else:
            # generate mask using element wise bool operation
            mask_face0 = np.abs(1/np.cos(grid_phi)/(np.tan(grid_theta) + 1e-16)) > 1
            mask_face1 = np.abs(1/np.cos(grid_phi-np.pi/2)/(np.tan(grid_theta) + 1e-16)) > 1
            mask_face2 = np.abs(1/np.cos(grid_phi-np.pi)/(np.tan(grid_theta) + 1e-16)) > 1
            mask_face3 = np.abs(1/np.cos(grid_phi-3*np.pi/2)/(np.tan(grid_theta) + 1e-16)) > 1
            
            if face_num == 4:
                mask_center = (grid_theta < np.pi/2)
                
                # combine all masks 
                mask_face = mask_center*mask_face0*mask_face1*mask_face2*mask_face3
                mask_face = mask_face.flatten()
                
                phi   = grid_phi.flatten()[mask_face]
                theta = grid_theta.flatten()[mask_face]
                
                # normalized image coordinates
                u = 1 - np.tan(theta)*np.sin(phi)
                v = 1 - np.tan(theta)*np.cos(phi)
                
            elif face_num == 5:
                mask_center = (grid_theta > np.pi/2)
                
                # combine all masks 
                mask_face = mask_center*mask_face0*mask_face1*mask_face2*mask_face3
                mask_face = mask_face.flatten()
                
                phi   = grid_phi.flatten()[mask_face]
                theta = grid_theta.flatten()[mask_face]
                
                # normalized image coordinates
                u = 1 + np.tan(theta)*np.sin(phi)
                v = 1 - np.tan(theta)*np.cos(phi)
        
        points  = np.column_stack((v, u))
        
        return points, mask_face
    
    
    def cube2sphere_std(self, cube_list: list = [], fov: float = np.pi/2, 
                        resolution: tuple = (256,512), 
                        order: Optional[list] = None):
        """
            This function will verify inputs and then call proj2omnimage() to do the projection.
            
            Parameters
            ----------    
            cube_list : a list of cubic images
                If 'position' is not given and there are 6 images in the list, then the order of the 6 images has to be:
                [ 0th:  back  |  1st:  left  |  2nd:  front  |  3rd:  right  |  4th:  top  |  5th:  bottom ]
                
            fov: float 
                Field of view of the 6 images
                
            resolution : tuple
                The required resolution for the ouput omnidirectional image, default is 256x512 (theta, phi).
                
            order : a list of integer 
                For each image in the cube_list, the number denotes the direction of the image.
                [0,1,2,3,4,5] -> default order
                [5,4,3,2,1,0] -> inverse order, i.e. the first image in the cube_list is the bottom and the second image is the top etc. 
                If there are only 3 images in the cube_list, then only the first 3 numbers will be considered.
    
            Returns
            -------
            Omni_image : np.array
                An omnidirectional image generated from the given 6 cubic images.
            
            Examples
            --------
            >>> from DepthMap_Tools import Depth_tool
            >>> tool_obj = Depth_tool()
            >>> tool_obj.sphere2cube(Omni_obj)
            >>> Omni_new = tool_obj.cube2sphere_std( tool_obj._cubemap )

        """
        if len(cube_list) == 0:
            if len(self._depthmap) == 6:
                warnings.warn('Empty cube list, using cubic depth maps.' )
                cube_list = self._depthmap.copy()
            elif len(self._cubemap) == 6:
                warnings.warn('Empty cube list, using cubic maps.' )
                cube_list = self._cubemap.copy()
            else:
                raise ValueError('Bad input! Invalid input image list.')                
        for cube in cube_list:
            if cube.shape != cube_list[0].shape:            
                raise ValueError('Bad input! All given images should have the same size.')
        
        if len(resolution) == 1:
            resolution = (resolution, resolution)
        elif len(resolution) != 2:
            raise ValueError('Inpur Error! Resolution must contain 1 or 2 number.')              
        if resolution[0] <= 0 or resolution[1] <= 0:
            raise ValueError('Inpur Error! Resolution must be positive.')
        
        # reorder the cubelist
        if order is not None:
            if len(order) < len(cube_list):
                raise ValueError('Inpur Error! The length of "order" should be equal or larger than the length of "cube_list".') 
            temp = cube_list
            cube_list = [ [] for i in range(len(temp))]
            for ind, img in enumerate(temp):
                cube_list[ order[ind] ] = img         
                
        # generate omnidirectional image
        self._omnimage = self.proj2omnimage(cube_list, fov, resolution)
    
    
    def proj2omnimage(self, cube_list: list, fov: float, resolution: tuple):
        """
            It projects a list of cubic images to an omnidirectional image.
            Since it passes a pixel at a time, it costs more time than the faster version.
                
            Parameters
            ----------    
            cube_list : a list of cubic images
                If 'position' is not given and there are 6 images in the list, then the order of the 6 images has to be:
                [ 0th:  back  |  1st:  left  |  2nd:  front  |  3rd:  right  |  4th:  top  |  5th:  bottom ]
                
            fov: float 
                Field of view of the 6 images
                
            resolution : tuple
                The required resolution for the ouput omnidirectional image, default is 256x512 (theta, phi).
                
            Returns
            -------
            texture : numpy.array 
                The omnidirectional image generated from the given cubic maps.
        """
        pixels = []
        cubelist_spline = []
        width, height, channel = cube_list[0].shape[1], cube_list[0].shape[0], cube_list[0].shape[2] 
    
        # generate grids on the sphere
        phi_grids, theta_grids = np.meshgrid( np.linspace(0, 2*np.pi, num=resolution[1], endpoint=False), \
                                               np.linspace(0, np.pi, num=resolution[0], endpoint=True) )
        phi_grids = phi_grids.flatten()
        theta_grids = theta_grids.flatten()
        
        # configure interpolation 
        up  = [np.tan(fov/2), np.tan(fov/2)]
        low = [-np.tan(fov/2), -np.tan(fov/2)]
        orders = [height, width]
        # Create a list of spline approximations for the cube_list.
        for ct in range(len(cube_list)):
            # attention: in numpy, indices for 3d data are [layer, row, column], 
            # so a image has width layers, height rows and 3 columns. Thus for 
            # the image, the 'reshape' is conducted column by column.
            spline = CubicSplines(low, up, orders, 
                                  np.reshape(cube_list[ct], (height * width, channel)))  
            cubelist_spline.append(spline)
        
        # obtain the texture
        for ct in range(phi_grids.shape[0]):
            facenum_pixel = self.angle2pixel(phi_grids[ct], theta_grids[ct])
            pixels.append(facenum_pixel)   
        # flip the order resulted from the 'reshape' 
        pixels = np.flip(np.array(pixels)[:,0,:],axis = -1)
        
        texture = np.zeros((pixels.shape[0], 3))
        for face in np.unique(pixels[:,2]):
            index = pixels[:,2] == face
            texture[index, :] = cubelist_spline[int(face)].interpolate(pixels[index, :2], diff=False)
        
        return texture.reshape([resolution[0], resolution[1], 3])
    
    
    def angle2pixel(self, phi: float, theta: float):
        """
            It projects a given pixel on the sphere to the corresponding pixel on cubic faces.
                
            Parameters
            ----------    
            phi: float
                The horizontal angle of the pixel on the sphere. (From negative y direction)
                
            theta: float
                The vertical angle of the pixel on the sphere. (From positive z direction)
                
            Returns
            -------
            numpy.array: [face, x, y]
                face: the index of the cubic face where the projected pixel locates;
                x, y: location of the projected pixel under image coordinate.
        """
        face,z = self.which_face(phi,theta)
        
        if face == 0:
            x, y = np.tan(phi), -z
        elif face == 1:
            x, y = np.tan(phi - np.pi/2), -z
        elif face == 2:
            x, y = np.tan(phi - np.pi)  , -z
        elif face == 3:
            x, y = np.tan(phi - 3*np.pi/2), -z
        elif face == 4:
            x = -np.tan(theta)*np.sin(phi)
            y = -np.tan(theta)*np.cos(phi)
        else:
            x = np.tan(theta)*np.sin(phi)
            y = -np.tan(theta)*np.cos(phi)
        return np.array([[face, x, y]])
        
    
    def which_face(self, phi: float, theta: float):
        """
            It returns the index of the cubic face where the given pixel on the sphere corresponds to 
            as well as the z coordinate of the prjected pixel (can be used as 'y' under image coordinate).
                
            Parameters
            ----------    
            phi: float
                The horizontal angle of the pixel on the sphere. (From negative y direction)
                
            theta: float
                The vertical angle of the pixel on the sphere. (From positive z direction)
                
            Returns
            -------
            face, z
                face: the index of the cubic face where the projected pixel locates;
                z: z coordinate of the prjected pixel.
        """    
        if phi <= np.pi/4 or phi > 7*np.pi/4:
            z = 1/np.cos(phi)/(np.tan(theta) + 1e-16)
            if z < -1:
                face, z = 5, -1
            elif z > 1:
                face, z = 4, 1
            else:
                face = 0
        elif np.pi/4 < phi <= 3*np.pi/4:
            z = 1/np.cos(phi-np.pi/2)/(np.tan(theta) + 1e-16)
            if z < -1:
                face, z = 5, -1
            elif z > 1:
                face, z = 4, 1
            else:
                face = 1
        elif 3*np.pi/4 < phi <= 5*np.pi/4:
            z = 1/np.cos(phi-np.pi)/(np.tan(theta) + 1e-16)
            if z < -1:
                face, z = 5, -1
            elif z > 1:
                face, z = 4, 1
            else:
                face = 2
        elif 5*np.pi/4 < phi <= 7*np.pi/4:
            z = 1/np.cos(phi-3*np.pi/2)/(np.tan(theta) + 1e-16)
            if z < -1:
                face, z = 5, -1
            elif z > 1:
                face, z = 4, 1
            else:
                face = 3
        return face, z
        

    def sphere2cube (self, cam:'cam360', resolution: tuple=(256,256), dist: float=None, is_depth: bool = False):
        """
            Description: 
            ----------
            It generates cubic maps from the given omnidirectional image.    
            
            Parameters
            ----------    
            cam: object
                camera320 object to be projected;
            
            resolution: tuple
                resolution of the cubic maps;
                
            dist: float
                distance between the tangent plane and the center of the sphere;
                
            is_depth: bool
                flag suggesting whether we project depthmap or not;
                
            Examples
            --------
            >>>> sphere2cube(Omni_obj, rsesolution=(256,256))
        """
    # input verification
        if ( (not is_depth) and cam.texture is None ) or (is_depth and cam.depth is None) :
            raise ValueError('INPUT ERROR! Empty cam360 object.')  
        if resolution[0] <= 0 or resolution[1] <= 0:
            raise ValueError('INPUT ERROR! Resolutions must be positive.')  
        # if dist is not given, use the default value    
        if dist is None:
            dist = self._dist
            
    # generate cubic maps
        cubic_maps = []        
        # enlarge field of view to include more information for further cube->sphere reconstruction4
        delta_angle = np.pi/2
        
        # back view
        cubic_maps.append(self.cube_projection(cam, (0,         np.pi/2, delta_angle, delta_angle), resolution, is_depth=is_depth))
        # left view 
        cubic_maps.append(self.cube_projection(cam, (np.pi/2,   np.pi/2, delta_angle, delta_angle), resolution, is_depth=is_depth))
        # front view
        cubic_maps.append(self.cube_projection(cam, (np.pi,     np.pi/2, delta_angle, delta_angle), resolution, is_depth=is_depth))
        # right view
        cubic_maps.append(self.cube_projection(cam, (3*np.pi/2, np.pi/2, delta_angle, delta_angle), resolution, is_depth=is_depth))
        # bottom view - from bottom to top
        cubic_maps.append(self.cube_projection(cam, (np.pi,     0,       delta_angle, delta_angle), resolution, is_depth=is_depth))
        # top view - from top to bottom
        cubic_maps.append(self.cube_projection(cam, (np.pi,     np.pi,   delta_angle, delta_angle), resolution, is_depth=is_depth))
    
    # save cubic maps (texture or depthmap)
        if (not is_depth):
            self._cubemap = cubic_maps
        if is_depth:
            self._depthmap = cubic_maps
        
        return cubic_maps
    
    
    def cube_projection( self, cam:'cam360', direction: tuple,
                         resolution: tuple=(256,256), dist: float = None,
                         is_depth: bool = False) -> np.array:
        """
            Description: 
            ----------
            It projects a omnidirectional image/depth to its tangent plane(or the plane parallel to its tangent plane) on the given direction.    
            
            Parameters
            ----------    
            cam: object
                camera320 object to be projected
                 
            direction: tuple (phi, theta, fov_phi, fov_theta)
                phi, theta -> the direction of normal line to the tangent plan;
                fov_phi, fov_theta -> field of view on phi and theta;
                
            resolution: tuple
                resolution of the output image;
                
            dist: float
                distance between the tangent plane and the center of the sphere ;
            
            is_depth: bool
                flag suggesting whether we project depthmap or not;
                
            Returns
            -------
            projection: np.array
                the projected cubic map of the given omnidirectional image on the given plane;
                
            Examples
            --------
            >>> cube_projection(Omni_obj, direction=(np.pi, np.pi/2, np.pi/2, np.pi/2), resolution=(320,320))
        """
    # input verification
        if len(direction)!=2 and len(direction)!=4:
            raise ValueError('INPUT ERROR! the input direction must contain 2 angles as (phi, theta) or contain 4 angles as (phi, theta, fov_phi, fov_theta)')   
        elif len(direction)==2:
            center_phi   = direction[0]
            center_theta = direction[1]
            fov_phi   = np.pi/2
            fov_theta = np.pi/2
        else:
            center_phi   = direction[0]
            center_theta = direction[1]
            fov_phi   = direction[2]
            fov_theta = direction[3]
            
        # if dist is not given, use the default value    
        if dist is None:
            dist = self._dist
        elif dist < 1:
            raise ValueError('INPUT ERROR! The distance between the tangent plane and the center of the sphere should be greater than 1')   
        
        if center_phi < 0 or center_phi >= 2*np.pi :
            raise ValueError('INPUT ERROR! Phi of the normal line should belong to [0, 2*pi)')   
        if center_theta < 0 or center_theta > np.pi:
            raise ValueError('INPUT ERROR! theta of the normal line should belong to [0, pi]')   
        if fov_phi < 0 or fov_phi >= np.pi:
            raise ValueError('INPUT ERROR! fov_phi should belong to [0, pi)')   
        if fov_theta < 0 or fov_theta >= np.pi:
            raise ValueError('INPUT ERROR! fov_theta should belong to [0, pi)') 
        if resolution[0] <= 0 or resolution[1] <= 0:
            raise ValueError('INPUT ERROR! Resolutions must be positive.')  
    
    # generate pixel grids    
        # comput the relative image size
        half_height= dist*np.tan(fov_theta/2)        
        half_width = dist*np.tan(fov_phi/2)
        # compute pixels' positions on the image
        width_grids = np.linspace(-half_width , half_width , num=resolution[0], endpoint=True)
        height_grids= np.linspace(-half_height, half_height, num=resolution[1], endpoint=True)
        # generate pixels grids
        width_grids, height_grids = np.meshgrid(width_grids,height_grids)
        
    # compute the corresponding spherical coordinate for every pixel
        phi_range, theta_range = self.cartesian2spherical(center_phi, center_theta, width_grids, height_grids, dist)
    
    # obtain the texture/depth
        # flatten theta and phi to use the get_texture_at() method
        phi   = phi_range.flatten()
        theta = theta_range.flatten()        
        if is_depth==False:
            # get the texture and save it to the output cubemap list
            texture_vec = cam.get_texture_at(theta, phi)
            projection  = texture_vec.T.reshape( resolution[1], resolution[0], 3)
        else:
            # get the depthmap and save it to the output cubemap list
            texture_vec = cam.get_depth_at(theta, phi)
            projection  = texture_vec.T.reshape( resolution[1], resolution[0])
            
        return projection


    def cartesian2spherical( self, phi:float, theta:float, 
                             width_grids: np.array, height_grids: np.array, dist: float = None) -> tuple:
        """
            Description:
            ----------
            It computes the spherical coordinates of the given pixel grids.
                
            Parameters
            ----------    
            phi: float
                the horizontal angle (from negative y axis) of the normal line;
                
            theta: float
                the vertical angle (from positive z axis) of the normal line;
                
            width_grids: np.array
                positions of points on the image plane;
                
            height_grids: np.array
                positions of points on the image plane;
                
            dist: float
                distance between the tangent plane and the center of the sphere;
                
                         width
              z ^        ------                 
                |   y    \--\--\ heigh
                |   /     \--\--\
                |  /       \--\--\
                | /
                |/
                --------------> x
            
            Returns
            -------
            phi_grids: np.array
                phi positions of points under the polar coordinate system
                
            theta_grids: np.array
                theta positions of points under the polar coordinate system
                
            Examples
            --------
            >>> cartesian2spherical(center_phi, center_theta, width_grids, height_grids, dist)
        """  
        # if dist is not given, use the default value    
        if dist is None:
            dist = self._dist
            
        # get the euler coordinate of the tangent point
        center_x, center_y, center_z = pol2eu(theta, phi, dist)
        # compute the length of the projected normal line segment
        prj_dist = dist*np.sin(theta)
        # compute z-axis positions of each point
        zeta_range = -height_grids*np.sin(theta) + center_z
        
        # compute the cooresponding polar coordinate for each image point
        theta_grids = np.arccos(zeta_range/np.sqrt(dist**2 + height_grids**2 + width_grids**2))
        phi_grids   = np.arctan2(width_grids,  prj_dist+height_grids*np.cos(theta)) + phi
        
        # make sure every angle is valid phi: (0,2pi), theta:(0,pi)
        phi_grids[phi_grids<0] = phi_grids[phi_grids<0] + 2*np.pi
        phi_grids[phi_grids>=2*np.pi] = phi_grids[phi_grids>=2*np.pi] - 2*np.pi
        
        theta_grids[theta_grids<0] = np.abs(theta_grids[theta_grids<0])
        theta_grids[theta_grids>np.pi] = 2*np.pi - theta_grids[theta_grids>np.pi]
        
        return phi_grids, theta_grids
    
    
    def estimate_cubic_foclen(self, depthmap: list = None, fov: tuple = None) -> list:
        
        if fov is None or len(fov) != 2:
            raise ValueError('Input ERROR! Invalid fov (field of view)')
        elif fov[0] <= 0 or fov[1] <= 0:
            raise ValueError('Input ERROR! Field of view of a image should be greater than 0')
            
        if depthmap is None:
            if len(self.depthmap) > 0:
                print('Depth list is not given; the cubic depth maps inside the object will be used!')
                depthmap = self.depthmap
            else:
                raise ValueError('Input ERROR! No valid depth map is given')
                
        fx = []
        fy = []
        cx = (depthmap[0].shape[1]-1)/2
        cy = (depthmap[0].shape[0]-1)/2
        
        half_x = np.tan(fov[1]/2)
        half_y = np.tan(fov[0]/2)
        
        # here in np, ndarry is organized in [column, row, channel]
        x = np.linspace(start = 0, stop = depthmap[0].shape[1]-1, num = cx*2 + 1)/cx - 1
        y = np.linspace(start = 0, stop = depthmap[0].shape[0]-1, num = cy*2 + 1)/cy - 1
        grid_x, grid_y = np.meshgrid(x, y)
        
        norm_grid_x = half_x*grid_x
        norm_grid_y = half_y*grid_y
        
        grid_theta = np.pi/2 + np.arctan2(norm_grid_y, np.sqrt(norm_grid_x**2+1))
        grid_phi = np.arctan2(norm_grid_x, 1)
        
        for depth in depthmap:
            grid_Y = depth*np.cos(grid_theta)
            grid_X = depth*np.sin(grid_theta)*np.sin(grid_phi)
            grid_Z = depth*np.sin(grid_theta)*np.cos(grid_phi)
            
            pix_x = (grid_x + 1)*cx - cx
            pix_y = (grid_y + 1)*cy - cy

            fx.append(np.mean( (grid_Z*pix_x/grid_X) ))
            fy.append(np.mean( -(grid_Z*pix_y/grid_Y) ))
        return fx, fy
        
        
###### adapted from colmap ######
    def load_depthmap(self, path_to_file: list):
        if len(path_to_file)==6:
            if len(self._depthmap) != 0:
                warnings.warn("Depth maps will be replaced!")
                self._depthmap = []
            for ct in range(6):
                raw_depthmap = read_array(path_to_file[ct])
                depth_map = self.filt_depthoutliers(raw_depthmap)
                self._depthmap.append(np.expand_dims(depth_map, axis = 2))
                
        elif len(path_to_file)==4:
            if len(self._depthmap) != 0:
                warnings.warn("Depth maps will be replaced!")
                print('Inputs are treated as back, left, front and righ view')
                self._depthmap = []
            
            for ct in range(4):
                raw_depthmap = read_array(path_to_file[ct])
                depth_map = self.filt_depthoutliers(raw_depthmap)
                self._depthmap.append(np.expand_dims(depth_map, axis = 2))
            self._depthmap.append(np.zeros(self._depthmap[1].shape))
            self._depthmap.append(np.zeros(self._depthmap[1].shape))
        else :
            raise ValueError('Bad input! Only support 4 and 6 depthmaps.')
            
            
    def filt_depthoutliers(self, depth_map: np.array) -> np.array:
        min_depth, max_depth = np.percentile(depth_map, [10, 90])
        depth_map[depth_map < min_depth] = min_depth
        depth_map[depth_map > max_depth] = max_depth
        return depth_map
###### end of adapted codes ###### 